import os
import pandas as pd
import sys

configfile: "../config.yaml"

FASTAFILES = [el[0] for el in pd.read_csv(config["genomes_list"], header=None).values]
FASTAEXT = {os.path.splitext(os.path.basename(el))[0]:os.path.splitext(os.path.basename(el))[1] for el in FASTAFILES}
GENOMES = list(FASTAEXT.keys())
OUTPUTPATH = config["output_dir"] #output directory will contain subdirectory with unimogs from integerisation pipeline, as well as placing all new output from current pipeline in subdirectories within it
PREFIX = config["prefix"]
INTEGERISATION = config["integerisation"]
JACCARD_DISTANCE = config["seq_jaccard_distance"]
COMMUNITIES = config["communities"]


def get_plasmid_to_community():
    plasmid_to_community = {}
    with open(COMMUNITIES) as communities_fh:
        for community_index, line in enumerate(communities_fh):
            plasmids = line.strip().split()
            for plasmid in plasmids:
                plasmid_to_community[plasmid] = community_index
    return plasmid_to_community

plasmid_to_community = get_plasmid_to_community()

def get_unimog(integerisation, genome1, genome2):
    unimog = ""
    if integerisation == "anno":
        community = plasmid_to_community[genome1]
        unimog = f"{OUTPUTPATH}/unimogs/relabelled/blocks/{community}_blocks.unimog"
    elif integerisation == "align":
        unimog = f"{OUTPUTPATH}/unimogs/{genome1}~{genome2}_align.unimog"
    return unimog

def get_dist_files(jaccard_tsv):
    files=[]
    with open(jaccard_tsv, "r") as f:
        next(f)  # skip header
        for line in f:
            plasmid_1, plasmid_2, jaccard = line.strip().split("\t")
            jaccard = float(jaccard)
            if jaccard <= JACCARD_DISTANCE:
                files.append(f"{OUTPUTPATH}/tmp_files/dists_pairwise/{plasmid_1}~{plasmid_2}.dist")
    return files

def get_timelimit(solver):
    if config["timelimit"]=="None":
        return ""
    else:
        solver_to_timelimit = {
            "GLPK": f"--tmlim {config['timelimit']}",
            "gurobi": f"TimeLimit={config['timelimit']}",
        }
        return solver_to_timelimit[solver]

rule all:
    input:
        matrix = f"{OUTPUTPATH}/{PREFIX}_matrix.dist",
        dcj_graph_outdir = f"{OUTPUTPATH}/dcj_graph"

rule unimog_to_ilp:
    input:
        unimog=lambda wildcards: get_unimog(INTEGERISATION, wildcards.genome1, wildcards.genome2)
    output:
        lp=f"{OUTPUTPATH}/tmp_files/ding/ilp/{{genome1}}~{{genome2}}.lp"
    params:
        genome1 = lambda wildcards: wildcards.genome1,
        genome2 = lambda wildcards: wildcards.genome2
    resources:
        mem_mb = lambda wildcards, attempt: attempt * config["unimog_to_ilp_mem"]
    conda: "../envs/ding.yaml"
    log: "logs/unimog_to_ilp/{genome1}~{genome2}.log"
    shell:
        """
        dingII generate {input.unimog} -mm --writeilp {output.lp} -p {params.genome1} {params.genome2} 2>{log}
        """

if config["ilp_solver"] == "GLPK":
    ruleorder: ilp_GLPK > ilp_gurobi
elif config["ilp_solver"] == "gurobi":
    ruleorder: ilp_gurobi > ilp_GLPK
else:
    raise RuntimeError(f"Unknown ILP solver: {config['ilp_solver']}")

rule ilp_gurobi:
    input:
        lp = f"{OUTPUTPATH}/tmp_files/ding/ilp/{{genome1}}~{{genome2}}.lp"
    output:
        solution = f"{OUTPUTPATH}/tmp_files/ding/solutions/{{genome1}}~{{genome2}}.sol",
    params:
        timelimit=get_timelimit(config["ilp_solver"]),
    resources:
        mem_mb = lambda wildcards, attempt: attempt * config["ilp_mem"]
    threads: 1
    log: "logs/ilp/gurobi/{genome1}~{genome2}.log"
    shell:
        """
        gurobi_cl \
          ResultFile={output.solution} \
          Threads={threads} \
          LogFile={log} \
          {params.timelimit} \
          {input.lp} \
          >/dev/null
        """


rule ilp_GLPK:
    input:
        lp = f"{OUTPUTPATH}/tmp_files/ding/ilp/{{genome1}}~{{genome2}}.lp"
    output:
        solution = f"{OUTPUTPATH}/tmp_files/ding/solutions/{{genome1}}~{{genome2}}.sol",
    params:
        timelimit=get_timelimit(config["ilp_solver"]),
        snakefile_dir = os.path.dirname(sys.argv[sys.argv.index("--snakefile")+1])
    resources:
        mem_mb = lambda wildcards, attempt: attempt * config["ilp_mem"]
    threads: 1
    log: "logs/ilp/GLPK/{genome1}~{genome2}.log"
    conda: "../envs/glpk.yaml"
    shell:
        """
        glpsol \
          --lp {input.lp} \
          -o {output.solution}.tmp \
          {params.timelimit} \
          2>&1 > {log}
        python {params.snakefile_dir}/glpk_sol_to_gurobi_sol.py <{output.solution}.tmp >{output.solution}
        rm {output.solution}.tmp
        """


rule dcj_dist:
    input:
        solution = f"{OUTPUTPATH}/tmp_files/ding/solutions/{{genome1}}~{{genome2}}.sol",
        unimog = lambda wildcards: get_unimog(INTEGERISATION, wildcards.genome1, wildcards.genome2)
    output:
        dist_file = f"{OUTPUTPATH}/tmp_files/dists_pairwise/{{genome1}}~{{genome2}}.dist",
        out_unimog_relabeled = f"{OUTPUTPATH}/unimogs/matched/{{genome1}}~{{genome2}}_matched.unimog"
    params:
        genome1 = lambda wildcards: wildcards.genome1,
        genome2 = lambda wildcards: wildcards.genome2
    resources:
        mem_mb = lambda wildcards, attempt: attempt * config["dcj_dist_mem"]
    conda: "../envs/ding.yaml"
    log: "logs/dcj_dist/{genome1}~{genome2}.log"
    shell:
        "dingII parsesol {input.unimog} --solgur {input.solution} --matching {output.out_unimog_relabeled} -p {params.genome1} {params.genome2} > {output.dist_file} 2>{log}"

rule dcj_matrix:
    input:
        dist_files = get_dist_files(f"{OUTPUTPATH}/jaccard/all_pairs_jaccard.tsv")
    output:
        matrix=f"{OUTPUTPATH}/{PREFIX}_matrix.dist"
    conda:
        "../envs/blocks.yaml"
    params:
        genomes= GENOMES,
        outputpath = OUTPUTPATH
    resources:
        mem_mb = lambda wildcards, attempt: attempt * config["dcj_matrix_mem"]
    script:
        "dcj_matrix.py"

rule dcj_tsv:
    input:
        dist_files = get_dist_files(f"{OUTPUTPATH}/jaccard/all_pairs_jaccard_distance.tsv")
    output:
        tsv=f"{OUTPUTPATH}/{PREFIX}_distances.tsv"
    conda:
        "../envs/blocks.yaml"
    params:
        genomes= GENOMES,
        outputpath = OUTPUTPATH
    resources:
        mem_mb = lambda wildcards, attempt: attempt * config["dcj_matrix_mem"]
    script:
        "dcj_tsv.py"

rule build_DCJ_graph:
    input:
        matrix = f"{OUTPUTPATH}/{PREFIX}_matrix.dist", #Path to file with matrix of DCJ distances
        communities=COMMUNITIES
    output:
        dcj_graph_outdir = directory(f"{OUTPUTPATH}/dcj_graph")
    conda:
        "../envs/blocks.yaml"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: config["build_DCJ_graph_mem"]*attempt
    params:
        dcj_dist_threshold=config["dcj_dist_threshold"],
        bh_connectivity = config["bh_connectivity"], #Minimum number of connections a plasmid need to be considered a blackhole plasmid
        bh_neighbours_edge_density = config["bh_neighbours_edge_density"], #Maximum number of edge density between blackhole plasmid neighbours to label the plasmid as blackhole
        small_subcommunity_size_threshold = config["small_subcommunity_size_threshold"] #Communities with size up to this parameter will be joined to neighbouring larger subcommunities
    script:
        "cluster_graph.py"
