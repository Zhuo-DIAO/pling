import os
import pymummer
from operator import attrgetter
from Bio import SeqIO
from Bio.SeqRecord import SeqRecord
from Bio.Seq import Seq
import shutil
import pandas as pd
from pathlib import Path
import geneseqclass as gs
import matplotlib.pyplot as plt
import numpy as np

GENOMES = [el[0] for el in pd.read_csv(config["genome_list"], header=None).values]
FASTAPATH = config["fastas"]
OUTPUTPATH = config["output_dir"]
PREFIX = config["prefix"]

rule all:
    input:
        names = expand(OUTPUTPATH+"/geneseq/{lineage}/{lineage}_blocks_names.txt", lineage=LINEAGES),
        ints = expand(OUTPUTPATH+"/geneseq/{lineage}/{lineage}_blocks_ints.txt", lineage=LINEAGES),
        map = expand(OUTPUTPATH+"/geneseq/{lineage}/{lineage}_blocks_maps.txt",lineage=LINEAGES)

rule gen_MSA_input:
    input:
        lambda wildcards: expand(f"{FASTAPATH}/{{genome}}.fna", genome=GENOMES)
    output:
        f"{OUTPUTPATH}/{PREFIX}.fna"
    threads: 1
    resources:
        mem_mb = lambda wildcards, attempt: attempt * 1000
    shell:
        "cat {input} > {output}"

rule nucmer:
    input:
        query = f"{OUTPUTPATH}/{PREFIX}.fna"
        ref = f"{OUTPUTHPATH}/{GENOMES[0]}.fna"
    output:
        nucmer = f"{OUTPUTPATH}/{PREFIX}.nucmer"
    run:
        prunner = pymummer.nucmer.Runner(
            params.ref,
            input.query,
            output.nucmer,
            min_id=90.0,     # minimum percent identity of match
            promer=False,
            maxmatch=True,
            breaklen=500,    # how far to look to join up matches before giving up
            min_length=800, # minimum length of match to report
        )
        prunner.run()

rule orient:
    input:
        nucmer = f"{OUTPUTPATH}/{PREFIX}.nucmer",
        sequences = lambda wildcards: expand(f"{FASTAPATH}/{{genome}}.fna", genome=GENOMES)
    params:
        ref = f"{OUTPUTHPATH}/{GENOMES[0]}.fna",
        genomes = GENOMES,
        fastapath = FASTAPATH,
        outputpath = OUTPUTPATH
    output:
        directory(f"{OUTPUTPATH}/oriented_fasta/"),
    threads: 1
    resources:
        mem_mb = lambda wildcards, attempt: attempt * 1000
    script:
        "orient.py"

rule bakta:
    input:
        genome = f"{FASTAPATH}/{{genome}}.fna"
    output:
        ann_dir = directory(f"{config['output_dir']}/annotated/{{genome}}_ann")
    conda:
        "bakta"
    threads: 1
    resources:
        mem_mb=lambda wildcards, attempt: attempt * 15000
    params:
        DB = directory(f"{config['bakta_db']}")
    shell:
        """
        bakta {input.genome} --skip-plot --db {params.DB} --prefix {wildcards.genome} \
         --translation-table 11 --threads {threads} --output {output.ann_dir} >{log} 2>&1
        """

rule panaroo:
    input:
        expand(f"{OUTPUTPATH}/bakta/{{genome}}/{{genome}}.gff3", genome=GENOMES)
    output:
        pangenome = directory(f"{OUTPUTPATH}/panaroo"),
        aln = directory(f"{OUTPUTPATH}/panaroo/aligned_gene_sequences")
    shell:
        "panaroo -i {input} -o {output.pangenome} --clean-mode moderate -a pan "

rule gen_minimap_input:
    input:
        align_dir=directory(f"{OUTPUTPATH}/panaroo/aligned_gene_sequences")
    output:
        f"{OUTPUTPATH}/minimap/input/{{genome}}.fna"
    threads: 1
    resources:
        mem_mb = lambda wildcards, attempt: attempt * 1000
    params:
        out_dir=f"{OUTPUTPATH}/minimap/input"
    run:
        seq_out = dict()
        for file in os.listdir(input.align_dir):
            file_name = str(Path(file))
            gene = str(Path(file).with_suffix(""))
            gene = gene.replace(".aln", "")
            seq_in = SeqIO.parse(f"{input.align_dir}/{file_name}", "fasta")
            for record in seq_in:
                genome, prokka_gene = record.id.split(';')
                blah = (str(record.seq)).replace('-','')
                seq = Seq(blah)
                if genome not in seq_out:
                    seq_out[genome] = [SeqRecord(seq, gene, "", "")]
                else:
                    (seq_out[genome]).append(SeqRecord(seq, gene, "", ""))
        for genome in seq_out:
            SeqIO.write(seq_out[genome], f"{params.out_dir}/{genome}.fna", "fasta")

rule minimap:
    input:
        reads=f"{OUTPUTPATH}/minimap/input/{{genome}}.fna",
        #ref=OUTPUTPATH+"/oriented_fasta/{lineage}/{genome}.fna"
        dir_ref = f"{OUTPUTPATH}/oriented_fasta/"
    output:
        f"{OUTPUTPATH}/minimap/output/{{genome}}.paf"
    threads: 3 #minimap default
    resources:
        mem_mb = lambda wildcards, attempt: attempt * 1000
    shell:
        "minimap2 -c {input.dir_ref}/{wildcards.genome}.fna {input.reads} > {output}"

rule consolidation:
    input:
        lambda wildcards: [OUTPUTPATH+"/minimap/{lineage}/output/"+genome+".paf" for genome in get_genomes(wildcards.lineage)],
    output:
        unimogpath = f"{OUTPUTPATH}/{PREFIX}_anno.unimog",
        map = f"{OUTPUTPATH}/{PREFIX}_map.txt"
    threads: 1
    resources:
        mem_mb = lambda wildcards, attempt: attempt * 1000
    params:
        pafs=f"{OUTPUTPATH}/minimap/output",
        genomes = GENOMES,
        fastapath = FASTAPATH,
        outputpath = OUTPUTPATH
    script:
        "consolidation.py"

rule blocks:
    input:
        names = OUTPUTPATH+"/geneseq/{lineage}/{lineage}_names.txt",
        ints = OUTPUTPATH+"/geneseq/{lineage}/{lineage}_ints.txt",
        map = OUTPUTPATH+"/geneseq/{lineage}/{lineage}_map.txt"
    output:
        names = OUTPUTPATH+"/geneseq/{lineage}/{lineage}_blocks_names.txt",
        ints = OUTPUTPATH+"/geneseq/{lineage}/{lineage}_blocks_ints.txt",
        map = OUTPUTPATH+"/geneseq/{lineage}/{lineage}_blocks_maps.txt"
    threads: 1
    resources:
        mem_mb = lambda wildcards, attempt: attempt * 1000
    params:
        path = OUTPUTPATH+"/geneseq/{lineage}",
        lineage = lambda wildcards: wildcards.lineage
    run:
        lin = gs.GeneSeq.from_cluster(params.path, params.lineage)
        block_lin = gs.BlockSeq.from_GeneSeq(lin)
        block_lin.to_cluster(params.path, params.lineage)
